<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html;charset=iso-8859-1">
<title>ReClaM: Class List</title>
<link href="ReClaM.css" rel="stylesheet" type="text/css">
<link href="tabs.css" rel="stylesheet" type="text/css">
</head><body>
<!-- Generated by Doxygen 1.4.7 -->
<div class="tabs">
  <ul>
    <li><a href="index.html"><span>Main&nbsp;Page</span></a></li>
    <li><a href="namespaces.html"><span>Namespaces</span></a></li>
    <li id="current"><a href="annotated.html"><span>Classes</span></a></li>
    <li><a href="files.html"><span>Files</span></a></li>
    <li><a href="pages.html"><span>Related&nbsp;Pages</span></a></li>
    <li><a href="examples.html"><span>Examples</span></a></li>
  </ul></div>
<div class="tabs">
  <ul>
    <li id="current"><a href="annotated.html"><span>Class&nbsp;List</span></a></li>
    <li><a href="hierarchy.html"><span>Class&nbsp;Hierarchy</span></a></li>
    <li><a href="functions.html"><span>Class&nbsp;Members</span></a></li>
  </ul></div>
<h1>ReClaM Class List</h1>Here are the classes, structs, unions and interfaces with brief descriptions:<table>
  <tr><td class="indexkey"><a class="el" href="class_adp_b_p90a.html">AdpBP90a</a></td><td class="indexvalue">Offers the gradient-based optimization algorithm with individual adaptive learning rates by Silva and Almeida (Adaptive BackPropagation) </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_adp_b_p90b.html">AdpBP90b</a></td><td class="indexvalue">Offers the second version of the gradient descent based optimization algorithm with individual adaptive learning rates by Silva and Almeida (Adaptive BackPropagation). This optimization algorithm introduced by Silva and Almeida adds individual adaptive learning rates and weight-backtracking to standard steepest descent </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_balanced_classification_error.html">BalancedClassificationError</a></td><td class="indexvalue">The <a class="el" href="class_classification_error.html">ClassificationError</a> class returns the number of classification errors, rescaled by the class magnitudes </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_b_f_g_s.html">BFGS</a></td><td class="indexvalue">Offers methods to use the Broyden-Fletcher-Goldfarb-Shanno algorithm for the optimization of models </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_c___solver.html">C_Solver</a></td><td class="indexvalue">Quadratic Program Solver for the C-SVM </td></tr>
  <tr><td class="indexkey"><a class="el" href="struct_c___solver_1_1t_cache_entry.html">C_Solver::tCacheEntry</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_c___s_v_m.html">C_SVM</a></td><td class="indexvalue">Meta <a class="el" href="class_model.html">Model</a> for <a class="el" href="class_s_v_m.html">SVM</a> training </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_c_e.html">CE</a></td><td class="indexvalue">Offers an (E)rror measure for (C)lassification tasks, that can be used for monitoring, but not for training </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_c_g.html">CG</a></td><td class="indexvalue">Offers methods to use the Conjugate Gradients algorithm for the optimization of models </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_classification_error.html">ClassificationError</a></td><td class="indexvalue">Returns the number of classification errors </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_component_wise_model.html">ComponentWiseModel</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_concatenated_model.html">ConcatenatedModel</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_cross_entropy.html">CrossEntropy</a></td><td class="indexvalue">Error measure for classication tasks that can be used as the objective function for training </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_cross_entropy_independent.html">CrossEntropyIndependent</a></td><td class="indexvalue">Error measure for classification tasks of non exclusive attributes that can be used for model training </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_c_v_error.html">CVError</a></td><td class="indexvalue"><a class="el" href="class_error_function.html">ErrorFunction</a> based on a cross validation procedure </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_c_v_model.html">CVModel</a></td><td class="indexvalue">Collection of sub-models for cross validation </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_d_f___cross_entropy.html">DF_CrossEntropy</a></td><td class="indexvalue">Error measure for classication tasks that can be used as the objective function for training </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_d_f___cross_entropy_independent.html">DF_CrossEntropyIndependent</a></td><td class="indexvalue">Error measure for classification tasks of non exclusive attributes that can be used for model training </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_d_f___mean_squared_error.html">DF_MeanSquaredError</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_diag_gauss_kernel.html">DiagGaussKernel</a></td><td class="indexvalue">Guassian Kernel with independent scaling of every axis </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_early_stopping.html">EarlyStopping</a></td><td class="indexvalue">Used for monitoring purposes, to avoid overfitting </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_error_function.html">ErrorFunction</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_error_measures.html">ErrorMeasures</a></td><td class="indexvalue">Various error measures (not for training!) </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_f_f_net.html">FFNet</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_general_gauss_kernel.html">GeneralGaussKernel</a></td><td class="indexvalue">General Guassian Kernel </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_i_rprop_minus.html">IRpropMinus</a></td><td class="indexvalue">This class offers methods for the usage of the improved Resilient-Backpropagation-algorithm without weight-backtracking </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_i_rprop_minus_power.html">IRpropMinusPower</a></td><td class="indexvalue">This class offers methods for the usage of the improved Resilient-Backpropagation-algorithm without weight-backtracking enhanced with Power </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_i_rprop_minus_trig_power.html">IRpropMinusTrigPower</a></td><td class="indexvalue">This class offers methods for the usage of the improved Resilient-Backpropagation-algorithm without weight-backtracking enhanced with Trig and Power </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_i_rprop_plus.html">IRpropPlus</a></td><td class="indexvalue">This class offers methods for the usage of the improved Resilient-Backpropagation-algorithm with weight-backtracking </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_kernel_function.html">KernelFunction</a></td><td class="indexvalue">Definition of a kernel function as a ReClaM model </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_linear_kernel.html">LinearKernel</a></td><td class="indexvalue">Linear Kernel, parameter free </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_linear_model.html">LinearModel</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_linear_output_tanh_net.html">LinearOutputTanhNet</a></td><td class="indexvalue">Offers a predefined feed-forward neural network, which uses the "tanh" activation function for the hidden neurons and linear functions for the output neurons </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_lin_out_f_f_net.html">LinOutFFNet</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_lin_out_m_s_e_b_f_f_net.html">LinOutMSEBFFNet</a></td><td class="indexvalue">Offers the functions to create and to work with a a (F)eed-(F)orward (Net)works with (Lin)ear (Out)put and with explicit defined neuron-to-(B)ias connections. The network is combined with the (M)ean (S)quared (E)rror measure. This combination is created due to computational efficiency </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_lin_out_m_s_e_f_f_net.html">LinOutMSEFFNet</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_l_m_s_e_f_f_net.html">LMSEFFNet</a></td><td class="indexvalue">Offers the functions to create and to work with a feed-forward network with explicit defined neuron-to-bias connections. The network is combined with the mean squared error measure. This combination is created due to computational efficiency </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_mean_squared_error.html">MeanSquaredError</a></td><td class="indexvalue">Calculates the mean squared error </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_model.html">Model</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_model_interface.html">ModelInterface</a></td><td class="indexvalue">Realizes the communication between the different modules </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_m_s_e_f_f_net.html">MSEFFNet</a></td><td class="indexvalue">Offers the functions to create and to work with a feed-forward network combined with the mean squared error measure. This combination is created due to computational efficiency </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_m_s_e_r_b_f_net.html">MSERBFNet</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_m_s_e_r_n_net.html">MSERNNet</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="classnegative_b_k_t_a.html">negativeBKTA</a></td><td class="indexvalue">Balanced version of the <a class="el" href="classnegative_k_t_a.html">negativeKTA</a> </td></tr>
  <tr><td class="indexkey"><a class="el" href="classnegative_k_t_a.html">negativeKTA</a></td><td class="indexvalue">Implementation of the negative Kernel Target Alignment (KTA) as proposed by Nello Cristianini </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_net_params.html">NetParams</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="classopt_c_m_a.html">optCMA</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="classopt_grid.html">optGrid</a></td><td class="indexvalue">Optimize by trying out a grid of configurations </td></tr>
  <tr><td class="indexkey"><a class="el" href="classopt_grid_nested.html">optGridNested</a></td><td class="indexvalue">Nested grid search </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_optimizer.html">Optimizer</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="classopt_point_search.html">optPointSearch</a></td><td class="indexvalue">Optimize by trying out predefined configurations </td></tr>
  <tr><td class="indexkey"><a class="el" href="classopt_sigmoid_fit.html">optSigmoidFit</a></td><td class="indexvalue">Optimize a sigmoid after <a class="el" href="class_s_v_m.html">SVM</a> outputs to turn them into probability estimates </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_paraboloid.html">Paraboloid</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_params.html">Params</a></td><td class="indexvalue">This class offers methods for easily using configuration files to change the values of variables in your programs </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_partitioning.html">Partitioning</a></td><td class="indexvalue">Defined a partitioning of a set of training points and labels as it is required for a cross validation procedure </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_polynomial_kernel.html">PolynomialKernel</a></td><td class="indexvalue">Polynomial Kernel </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_proben_b_net.html">ProbenBNet</a></td><td class="indexvalue">This special network is optimal for benchmark tests with the "proben 1" set </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_proben_net.html">ProbenNet</a></td><td class="indexvalue">This special network is optimal for benchmark tests with the "proben 1" set </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_quickprop.html">Quickprop</a></td><td class="indexvalue">This class offers methods for using the popular heuristic "Quickprop" optimization algorithm </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_radius_margin.html">RadiusMargin</a></td><td class="indexvalue">Squared Radius-Margin-Quotient </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_r_b_f_kernel.html">RBFKernel</a></td><td class="indexvalue">Definition of the RBF Gaussian kernel </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_r_b_f_net.html">RBFNet</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_rprop_minus.html">RpropMinus</a></td><td class="indexvalue">This class offers methods for the usage of the Resilient-Backpropagation-algorithm without weight-backtracking </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_rprop_plus.html">RpropPlus</a></td><td class="indexvalue">This class offers methods for the usage of the Resilient-Backpropagation-algorithm with weight-backtracking </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_sigmoid_model.html">SigmoidModel</a></td><td class="indexvalue"></td></tr>
  <tr><td class="indexkey"><a class="el" href="class_squared_error.html">SquaredError</a></td><td class="indexvalue">Calculates the sum-of-squares error </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_steepest_descent.html">SteepestDescent</a></td><td class="indexvalue">The simplest learning strategy </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_stochastic_gradient_descent.html">StochasticGradientDescent</a></td><td class="indexvalue">Learning strategies based on <a class="el" href="class_steepest_descent.html">SteepestDescent</a>, but with randomly chosen patterns </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_s_v_m.html">SVM</a></td><td class="indexvalue">Support Vector Machine (<a class="el" href="class_s_v_m.html">SVM</a>) as a ReClaM <a class="el" href="class_model.html">Model</a> </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_s_v_m___optimizer.html">SVM_Optimizer</a></td><td class="indexvalue"><a class="el" href="class_optimizer.html">Optimizer</a> for <a class="el" href="class_s_v_m.html">SVM</a> training by quadratic programming </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_tanh_net.html">TanhNet</a></td><td class="indexvalue">Offers a predefined feed-forward neural network, which uses the "tanh" activation function for hidden and output neurons </td></tr>
  <tr><td class="indexkey"><a class="el" href="class_variance_estimator.html">VarianceEstimator</a></td><td class="indexvalue">Offers the methods to deal with active learning of a neural network </td></tr>
</table>
<hr size="1"><address style="align: right;"><small>Generated on Wed Dec 16 13:07:16 2009 for ReClaM by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img src="doxygen.png" alt="doxygen" align="middle" border="0"></a> 1.4.7 </small></address>
</body>
</html>
